{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and functions\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = (32, 32)\n",
    "labels = ['ocean', 'ship', 'shore', 'sky']\n",
    "\n",
    "def normalize_rgb(r, g, b):\n",
    "    \"\"\"takes an input between 1 and 255 and returns a \n",
    "    value between 0 and 1\"\"\"\n",
    "    return (r/255.0, g/255.0, b/255.0)\n",
    "\n",
    "def extract_features_labels(file_list, feature_dims, rgb=True):\n",
    "    \"\"\"trains the classifier given a set of files\"\"\"\n",
    "    # X contains the features, Y contains the classes\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    num_files = len(file_list)\n",
    "    \n",
    "    # train on the file_list\n",
    "    for i, file in enumerate(file_list):\n",
    "        # metadata\n",
    "        if file[0] != \".\":\n",
    "            label, dataset_name, dataset_index = file.split(\"_\") # label_dataset_index.extension\n",
    "            dataset_index, extension = dataset_index.split(\".\") # index.extension\n",
    "            #print(\"%s %s %s\" % (classification, dataset_name, dataset_index))\n",
    "            # set the label\n",
    "            Y.append(label)\n",
    "\n",
    "            path = image_dir + \"/\" + file\n",
    "            im = Image.open(path)\n",
    "            if not rgb:\n",
    "                im = im.convert('L')\n",
    "            im = im.resize(feature_dims, resample=Image.LANCZOS)\n",
    "\n",
    "            # TODO\n",
    "            # Look into other methods for extracting features\n",
    "            # Ideas: \n",
    "            # 1. randomly sample a subset of pixels (consistent across all images)\n",
    "            # 2. use PCA to determine the pixels that have the most impact on the outcome\n",
    "            #  does this get too close to CNN?\n",
    "            #\n",
    "            \n",
    "            # extract features from each pixel\n",
    "            image_features = []\n",
    "            for x in range(0,feature_dims[0]):\n",
    "                for y in range(0,feature_dims[1]):\n",
    "                    if rgb:\n",
    "                        r, g, b = im.getpixel((x, y))\n",
    "                        r, g, b = normalize_rgb(r, g, b)\n",
    "                        image_features.extend([r, g, b])\n",
    "                    else:\n",
    "                        pixel_value = im.getpixel((x, y))\n",
    "                        feature = pixel_value/255.0\n",
    "                        image_features.append(feature)\n",
    "            X.append(image_features)\n",
    "\n",
    "            #print(\"%s %s %s\" % (r, g, b))\n",
    "            if rgb:\n",
    "                new_name = (\"%s_%s_%s_rgb.%s\" % (label, dataset_name, dataset_index, \"png\"))\n",
    "            else:\n",
    "                new_name = (\"%s_%s_%s_gray.%s\" % (label, dataset_name, dataset_index, \"png\"))\n",
    "            im.save(tmp_dir + \"/\" + new_name, \"PNG\")\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(\"processed %d out of %d images\" % (i, num_files))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd = C:\\Users\\jchadwick\\Documents\\ml-project\\code\n",
      "image_dir = ../images/combined\n",
      "tmp_dir = ../images/tmp\n"
     ]
    }
   ],
   "source": [
    "# directory structure\n",
    "cwd = os.getcwd()\n",
    "image_dir = \"../images/combined\"\n",
    "tmp_dir = \"../images/tmp\"\n",
    "print(\"cwd = \" + cwd)\n",
    "print(\"image_dir = \" + image_dir)\n",
    "print(\"tmp_dir = \" + tmp_dir)\n",
    "\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.mkdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0 out of 4140 images\n",
      "processed 100 out of 4140 images\n",
      "processed 200 out of 4140 images\n",
      "processed 300 out of 4140 images\n",
      "processed 400 out of 4140 images\n",
      "processed 500 out of 4140 images\n",
      "processed 600 out of 4140 images\n",
      "processed 700 out of 4140 images\n",
      "processed 800 out of 4140 images\n",
      "processed 900 out of 4140 images\n",
      "processed 1000 out of 4140 images\n",
      "processed 1100 out of 4140 images\n",
      "processed 1200 out of 4140 images\n",
      "processed 1300 out of 4140 images\n",
      "processed 1400 out of 4140 images\n",
      "processed 1500 out of 4140 images\n",
      "processed 1600 out of 4140 images\n",
      "processed 1700 out of 4140 images\n",
      "processed 1800 out of 4140 images\n",
      "processed 1900 out of 4140 images\n",
      "processed 2000 out of 4140 images\n",
      "processed 2100 out of 4140 images\n",
      "processed 2200 out of 4140 images\n",
      "processed 2300 out of 4140 images\n",
      "processed 2400 out of 4140 images\n",
      "processed 2500 out of 4140 images\n",
      "processed 2600 out of 4140 images\n",
      "processed 2700 out of 4140 images\n",
      "processed 2800 out of 4140 images\n",
      "processed 2900 out of 4140 images\n",
      "processed 3000 out of 4140 images\n",
      "processed 3100 out of 4140 images\n",
      "processed 3200 out of 4140 images\n",
      "processed 3300 out of 4140 images\n",
      "processed 3400 out of 4140 images\n",
      "processed 3500 out of 4140 images\n",
      "processed 3600 out of 4140 images\n",
      "processed 3700 out of 4140 images\n",
      "processed 3800 out of 4140 images\n",
      "processed 3900 out of 4140 images\n",
      "processed 4000 out of 4140 images\n",
      "processed 4100 out of 4140 images\n",
      "processed 0 out of 4140 images\n",
      "processed 100 out of 4140 images\n",
      "processed 200 out of 4140 images\n",
      "processed 300 out of 4140 images\n",
      "processed 400 out of 4140 images\n",
      "processed 500 out of 4140 images\n",
      "processed 600 out of 4140 images\n",
      "processed 700 out of 4140 images\n",
      "processed 800 out of 4140 images\n",
      "processed 900 out of 4140 images\n",
      "processed 1000 out of 4140 images\n",
      "processed 1100 out of 4140 images\n",
      "processed 1200 out of 4140 images\n",
      "processed 1300 out of 4140 images\n",
      "processed 1400 out of 4140 images\n",
      "processed 1500 out of 4140 images\n",
      "processed 1600 out of 4140 images\n",
      "processed 1700 out of 4140 images\n",
      "processed 1800 out of 4140 images\n",
      "processed 1900 out of 4140 images\n",
      "processed 2000 out of 4140 images\n",
      "processed 2100 out of 4140 images\n",
      "processed 2200 out of 4140 images\n",
      "processed 2300 out of 4140 images\n",
      "processed 2400 out of 4140 images\n",
      "processed 2500 out of 4140 images\n",
      "processed 2600 out of 4140 images\n",
      "processed 2700 out of 4140 images\n",
      "processed 2800 out of 4140 images\n",
      "processed 2900 out of 4140 images\n",
      "processed 3000 out of 4140 images\n",
      "processed 3100 out of 4140 images\n",
      "processed 3200 out of 4140 images\n",
      "processed 3300 out of 4140 images\n",
      "processed 3400 out of 4140 images\n",
      "processed 3500 out of 4140 images\n",
      "processed 3600 out of 4140 images\n",
      "processed 3700 out of 4140 images\n",
      "processed 3800 out of 4140 images\n",
      "processed 3900 out of 4140 images\n",
      "processed 4000 out of 4140 images\n",
      "processed 4100 out of 4140 images\n",
      "RGB:\n",
      "4140 observations\n",
      "Label counts:\n",
      "ocean - 504\n",
      "ship - 2347\n",
      "sky - 496\n",
      "\n",
      "Grayscale:\n",
      "4140 observations\n",
      "Label counts:\n",
      "ocean - 504\n",
      "ship - 2347\n",
      "sky - 496\n"
     ]
    }
   ],
   "source": [
    "# process images, create labels and features\n",
    "files = os.listdir(image_dir)\n",
    "\n",
    "# create rgb 32x32 pixel images for KNN and LDA/QDA\n",
    "X_rgb, y_rgb = extract_features_labels(files, IMAGE_SIZE)\n",
    "\n",
    "# create grayscale 28x28 pixel images for CNN\n",
    "X_gray, y_gray = extract_features_labels(files, (28, 28), rgb=False)\n",
    "\n",
    "# some stats about the dataset\n",
    "print(\"RGB:\")\n",
    "print(\"%s observations\" % (len(y_rgb)))\n",
    "assert len(X_rgb) == len(y_rgb)\n",
    "\n",
    "print(\"Label counts:\")\n",
    "for label in labels:\n",
    "    print(\"%s - %s\" % (label, y_rgb.count(label)))\n",
    "\n",
    "print(\"\\nGrayscale:\")\n",
    "print(\"%s observations\" % (len(y_gray)))\n",
    "assert len(X_gray) == len(y_gray)\n",
    "\n",
    "print(\"Label counts:\")\n",
    "for label in labels:\n",
    "    print(\"%s - %s\" % (label, y_gray.count(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export to data_rgb.csv and data_gray.csv\n",
    "with open('data_rgb.csv', 'w') as csvfile:\n",
    "    data_writer = csv.writer(csvfile, dialect='excel')\n",
    "    for row_num, label in enumerate(y_rgb):\n",
    "        row = [label]\n",
    "        row.extend(X_rgb[row_num])\n",
    "        data_writer.writerow(row)\n",
    "with open('data_gray.csv', 'w') as csvfile:\n",
    "    data_writer = csv.writer(csvfile, dialect='excel')\n",
    "    for row_num, label in enumerate(y_gray):\n",
    "        row = [label]\n",
    "        row.extend(X_gray[row_num])\n",
    "        data_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
